# Configuration for Cog ⚙️
# Reference: https://github.com/replicate/cog/blob/main/docs/yaml.md

build:
  # set to true if your model requires a GPU
  gpu: true

  # a list of ubuntu apt packages to install
  system_packages:
    - "ffmpeg"
    - "libmagic1"
    # - "libgl1-mesa-glx"
    # - "libglib2.0-0"

  # python version in the form '3.8' or '3.8.12'
  python_version: "3.10"

  # a list of packages in the format <package-name>==<version>
  python_packages:
     - "git+https://github.com/thomasmol/faster-whisper.git@master"
     - "transformers==4.25.1"
     - "accelerate==0.15.0"
     - "ffmpeg-python==0.2.0"
     - "pandas==1.5.0"
     - "torch==2.0.1"
     - "torchtext==0.15.2"
     - "torchvision==0.15.2"
     - "sacremoses==0.0.53"
     - "sentencepiece==0.1.97"
     - "tokenizers==0.13.2"
     - "tqdm==4.64.1"
     - "EasyNMT==2.0.2"
     - "nltk==3.8.1"
     - "transformers==4.25.1"
     - "pysrt==1.1.2"
     - "psutil==5.9.2"
     - "requests==2.28.2"
     - "pyannote.audio==3.0.1"
     - "python-magic==0.4.27"
     - "tensorboard==2.14.0"
     - "onnxruntime-gpu==1.16.0"


  # commands run after the environment is setup
  run:
    - "echo env is ready!"
    # - "echo another command if needed"

# predict.py defines how predictions are run on your model
predict: "predict.py:Predictor"
